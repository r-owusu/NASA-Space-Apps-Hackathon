#!/usr/bin/env python3
"""
Enhanced Multimessenger AI Analysis Platform
Advanced UI with improved visualizations and data input methods
"""

import streamlit as st
import pandas as pd
import numpy as np
import os
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
from datetime import datetime, timedelta
import requests
import json
import time
from model_loader import list_model_files, load_model_by_name
from inference import predict_df

# Simple report generation function
def generate_simple_report(df_results, analysis_params):
    """Generate a simple text report of the analysis results"""
    
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # Calculate basic stats
    total_pairs = len(df_results)
    positive_associations = len(df_results[df_results['pred_label'] == 1])
    negative_associations = total_pairs - positive_associations
    
    # Confidence breakdown
    high_conf = len(df_results[df_results['pred_prob'] >= 0.8])
    medium_conf = len(df_results[(df_results['pred_prob'] >= 0.5) & (df_results['pred_prob'] < 0.8)])
    low_conf = len(df_results[df_results['pred_prob'] < 0.5])
    
    avg_confidence = df_results['pred_prob'].mean()
    max_confidence = df_results['pred_prob'].max()
    
    report = f"""
MULTIMESSENGER AI ANALYSIS REPORT
=================================
Generated: {timestamp}

EXECUTIVE SUMMARY
-----------------
Total Event Pairs Analyzed: {total_pairs}
Positive Associations Found: {positive_associations} ({positive_associations/total_pairs*100:.1f}%)
Negative Associations: {negative_associations} ({negative_associations/total_pairs*100:.1f}%)

CONFIDENCE ANALYSIS
-------------------
Average Confidence Score: {avg_confidence:.3f}
Maximum Confidence Score: {max_confidence:.3f}
Threshold Used: {analysis_params.get('threshold', 'N/A')}

Confidence Level Breakdown:
- High Confidence (‚â•0.8): {high_conf} events ({high_conf/total_pairs*100:.1f}%)
- Medium Confidence (0.5-0.8): {medium_conf} events ({medium_conf/total_pairs*100:.1f}%)
- Low Confidence (<0.5): {low_conf} events ({low_conf/total_pairs*100:.1f}%)

TOP 10 MOST CONFIDENT ASSOCIATIONS
-----------------------------------
"""
    
    # Add top 10 results
    top_results = df_results.nlargest(10, 'pred_prob')
    for idx, (_, row) in enumerate(top_results.iterrows(), 1):
        report += f"""
{idx}. Event Pair
   Confidence: {row['pred_prob']:.4f}
   Classification: {'Same Event' if row['pred_label'] == 1 else 'Different Events'}
   Time Difference: {row.get('dt', 'N/A')} seconds
   Angular Separation: {row.get('dtheta', 'N/A')} degrees
"""
    
    report += f"""

GENERATED BY: NASA Space Apps Hackathon - Multimessenger AI Platform
TIMESTAMP: {timestamp}
"""
    
    return report

# Page configuration
st.set_page_config(
    page_title="Multimessenger AI Observatory",
    page_icon="üåå",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for clean, functional UI
st.markdown("""
<style>
    /* Simple violet theme colors */
    :root {
        --primary-color: #9c88ff;
        --primary-light: #b4a5ff;
        --secondary-color: #e1d5ff;
        --background-card: #f8fafc;
        --text-primary: #1f2937;
        --text-secondary: #6b7280;
        --border-color: #e5e7eb;
        --success-color: #10b981;
        --warning-color: #f59e0b;
        --danger-color: #ef4444;
    }
    
    /* Global styles */
    .main .block-container {
        padding-top: 1rem;
        padding-bottom: 1rem;
        max-width: 1200px;
    }
    
    /* Typography */
    h1, h2, h3, h4, h5, h6 {
        font-family: -apple-system, BlinkMacSystemFont, sans-serif;
        color: var(--text-primary);
        margin-bottom: 0.5rem;
    }
    
    h1 { font-size: 2.2rem; font-weight: 600; }
    h2 { font-size: 1.8rem; font-weight: 600; }
    h3 { font-size: 1.4rem; font-weight: 500; }
    
    /* Violet header */
    .main-header {
        background: linear-gradient(135deg, var(--primary-color), var(--primary-light));
        padding: 2rem;
        border-radius: 12px;
        margin-bottom: 1.5rem;
        text-align: center;
        color: white;
    }
    
    .main-header h1 {
        font-size: 2.5rem;
        margin-bottom: 0.5rem;
        color: white;
    }
    
    .main-header p {
        font-size: 1.2rem;
        margin: 0;
        color: rgba(255,255,255,0.9);
    }
    
    /* Metric cards */
    .metric-container {
        background: var(--background-card);
        padding: 1.5rem;
        border-radius: 8px;
        border: 1px solid var(--border-color);
        margin: 0.5rem 0;
        text-align: center;
        transition: transform 0.2s;
    }
    
    .metric-container:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(156, 136, 255, 0.15);
    }
    
    .metric-container h3 {
        font-size: 1.5rem;
        margin-bottom: 0.25rem;
        color: var(--text-primary);
    }
    
    .metric-container h2 {
        font-size: 2rem;
        margin: 0.25rem 0;
        color: var(--primary-color);
    }
    
    .metric-container p {
        font-size: 0.9rem;
        color: var(--text-secondary);
        margin: 0;
    }
    
    /* Status badges */
    .status-badge {
        padding: 0.4rem 0.8rem;
        border-radius: 6px;
        font-size: 0.85rem;
        font-weight: 500;
        display: inline-block;
        margin: 0.2rem;
    }
    
    .status-success { background-color: #dcfce7; color: #16a34a; }
    .status-warning { background-color: #fef3c7; color: #d97706; }
    .status-danger { background-color: #fee2e2; color: #dc2626; }
    .status-info { background-color: #dbeafe; color: #2563eb; }
    
    /* Input cards */
    .input-card {
        background: var(--background-card);
        padding: 1.5rem;
        border-radius: 8px;
        border: 1px solid var(--border-color);
        margin: 1rem 0;
    }
    
    /* Analysis section */
    .analysis-section {
        background: var(--background-card);
        padding: 2rem;
        border-radius: 8px;
        border: 1px solid var(--border-color);
        margin: 1rem 0;
    }
    
    /* Results header */
    .results-header {
        background: var(--primary-color);
        padding: 1rem 1.5rem;
        border-radius: 8px 8px 0 0;
        color: white;
        font-weight: 600;
        font-size: 1.1rem;
        text-align: center;
    }
    
    /* Buttons */
    .stButton > button {
        background: var(--primary-color);
        color: white;
        border: none;
        padding: 0.75rem 1.5rem;
        border-radius: 6px;
        font-weight: 500;
        font-size: 1rem;
        transition: background-color 0.2s;
    }
    
    .stButton > button:hover {
        background: var(--primary-light);
    }
    
    /* Sidebar */
    .sidebar-section {
        background: var(--background-card);
        padding: 1.5rem;
        border-radius: 8px;
        margin: 1rem 0;
        border: 1px solid var(--border-color);
    }
    
    /* Confidence highlighting */
    .confidence-high { color: var(--success-color); font-weight: bold; }
    .confidence-medium { color: var(--warning-color); font-weight: bold; }
    .confidence-low { color: var(--danger-color); font-weight: bold; }
</style>
""", unsafe_allow_html=True)

# Simple, clean header
st.markdown("""
<div class="main-header">
    <h1>üåå Multimessenger AI Observatory</h1>
    <p>AI-powered analysis of multimessenger astronomical events</p>
</div>
""", unsafe_allow_html=True)

# Initialize session state with more variables
if 'current_data' not in st.session_state:
    st.session_state.current_data = None
if 'results' not in st.session_state:
    st.session_state.results = None
if 'model_loaded' not in st.session_state:
    st.session_state.model_loaded = False
if 'real_time_mode' not in st.session_state:
    st.session_state.real_time_mode = False
if 'api_data_cache' not in st.session_state:
    st.session_state.api_data_cache = {}

# Clean sidebar
st.sidebar.markdown("### üéõÔ∏è Control Panel")

st.sidebar.markdown('<div class="sidebar-section">', unsafe_allow_html=True)
st.sidebar.markdown("#### ü§ñ AI Model")

# Model selection
model_files = list_model_files()
model_choice = st.sidebar.selectbox(
    "Choose model:",
    ["(none)"] + model_files,
    key="model_selector",
    help="Select the AI model for analysis"
)

# Load model with enhanced feedback
model = None
scaler = None
metadata = None

if model_choice and model_choice != "(none)":
    try:
        model, scaler, metadata = load_model_by_name(model_choice)
        st.session_state.model_loaded = True
        
        st.sidebar.success("‚úÖ Model Active")
        
        if metadata:
            st.sidebar.info(f"""
            **Model Info:**
            - Algorithm: {metadata.get('best_model', 'Unknown')}
            - AUC Score: {metadata.get('best_auc', 'N/A'):.3f}
            - Date: {datetime.fromtimestamp(metadata.get('date', 0)).strftime('%Y-%m-%d') if metadata.get('date') else 'Unknown'}
            """)
            
    except Exception as e:
        st.sidebar.error("‚ùå Model Load Error")
        st.sidebar.caption(f"Error: {str(e)[:50]}...")
        st.session_state.model_loaded = False
else:
    st.session_state.model_loaded = False
    st.sidebar.info("‚ÑπÔ∏è Please select a model")

st.sidebar.markdown('</div>', unsafe_allow_html=True)

# Analysis parameters
st.sidebar.markdown('<div class="sidebar-section">', unsafe_allow_html=True)
st.sidebar.markdown("#### ‚öôÔ∏è Parameters")

threshold = st.sidebar.slider(
    "Confidence Threshold", 
    0.0, 1.0, 0.5, 0.05,
    help="Minimum confidence for positive associations"
)

# Simple options
with st.sidebar.expander("Advanced Options"):
    show_debug = st.checkbox("Show debug info")
    auto_refresh = st.checkbox("Auto-refresh")

st.sidebar.markdown('</div>', unsafe_allow_html=True)

# Simple educational section
st.sidebar.markdown('<div class="sidebar-section">', unsafe_allow_html=True)
st.sidebar.markdown("#### üìö Learn More")
st.sidebar.markdown("""
**Multimessenger Astronomy** combines observations from different cosmic messengers (gravitational waves, neutrinos, gamma rays, optical light) to study astronomical events.

**AI helps** identify subtle correlations between signals that might indicate they originate from the same astrophysical source.
""")
st.sidebar.markdown('</div>', unsafe_allow_html=True)

# Main content area
col1, col2 = st.columns([2, 1])

with col1:
    # Enhanced data input section
    st.markdown('<div class="analysis-section">', unsafe_allow_html=True)
    st.markdown("## üìä **Data Input Methods**")
    
    # Data input tabs
    tab1, tab2, tab3, tab4 = st.tabs([
        "üöÄ **Demo Data**", 
        "üìÇ **File Upload**", 
        "üåê **API Integration**", 
        "‚ö° **Real-time Input**"
    ])
    
    with tab1:
        st.markdown("### Generate Synthetic Multimessenger Data")
        
        col_a, col_b, col_c = st.columns(3)
        with col_a:
            n_events = st.number_input("Number of events", 10, 1000, 50)
        with col_b:
            event_types = st.multiselect(
                "Messenger types", 
                ['GW', 'Gamma', 'Neutrino', 'Optical', 'Radio'],
                default=['GW', 'Gamma', 'Neutrino', 'Optical']
            )
        with col_c:
            time_window = st.number_input("Time window (hours)", 0.1, 48.0, 24.0)
        
        if st.button("üöÄ **Generate Enhanced Demo Data**", key="gen_demo"):
            with st.spinner("Generating realistic multimessenger data..."):
                # Enhanced demo data generation
                np.random.seed(42)
                
                # More realistic parameter distributions
                data = {
                    'dt': np.random.exponential(1.0, n_events),
                    'dtheta': np.random.exponential(0.1, n_events),
                    'strength_ratio': np.random.lognormal(0, 1, n_events),
                    'ra': np.random.uniform(0, 360, n_events),
                    'dec': np.random.uniform(-90, 90, n_events),
                    'energy': np.random.lognormal(15, 2, n_events),  # Energy in eV
                    'snr': np.random.exponential(5, n_events),  # Signal-to-noise ratio
                    'distance': np.random.exponential(100, n_events),  # Distance in Mpc
                    'timestamp': [
                        datetime.now() - timedelta(hours=np.random.uniform(0, time_window))
                        for _ in range(n_events)
                    ]
                }
                
                # Ensure we have the requested messenger types
                if len(event_types) >= 2:
                    data['m1'] = np.random.choice(event_types, n_events)
                    data['m2'] = np.random.choice(event_types, n_events)
                    # Ensure m1 != m2
                    mask = data['m1'] == data['m2']
                    for i in np.where(mask)[0]:
                        options = [m for m in event_types if m != data['m1'][i]]
                        if options:
                            data['m2'][i] = np.random.choice(options)
                else:
                    st.error("Please select at least 2 messenger types")
                    st.stop()
                
                df = pd.DataFrame(data)
                st.session_state.current_data = df
                
                st.success(f"‚úÖ Generated {len(df)} multimessenger events with {len(event_types)} messenger types!")
                
                # Quick preview
                st.markdown("**Preview:**")
                st.dataframe(df.head(), width="stretch")
    
    with tab2:
        st.markdown("### Upload CSV Data File")
        
        uploaded_file = st.file_uploader(
            "Choose a CSV file",
            type="csv",
            help="Required columns: dt, dtheta, strength_ratio. Optional: m1, m2, ra, dec"
        )
        
        if uploaded_file is not None:
            try:
                df = pd.read_csv(uploaded_file)
                st.session_state.current_data = df
                
                # Validate required columns
                required_cols = ['dt', 'dtheta', 'strength_ratio']
                missing_cols = [col for col in required_cols if col not in df.columns]
                
                if missing_cols:
                    st.error(f"‚ùå Missing required columns: {missing_cols}")
                else:
                    st.success(f"‚úÖ File uploaded successfully: {len(df)} events")
                    
                    # Data quality check
                    with st.expander("üìä Data Quality Report"):
                        col_q1, col_q2, col_q3 = st.columns(3)
                        with col_q1:
                            st.metric("Total Events", len(df))
                        with col_q2:
                            missing_data = df.isnull().sum().sum()
                            st.metric("Missing Values", missing_data)
                        with col_q3:
                            valid_range = len(df[(df['dt'] >= 0) & (df['dtheta'] >= 0)])
                            st.metric("Valid Ranges", f"{valid_range}/{len(df)}")
                    
                    st.dataframe(df.head(), width="stretch")
                    
            except Exception as e:
                st.error(f"‚ùå Error reading file: {e}")
    
    with tab3:
        st.markdown("### Real Astronomical Data APIs")
        
        api_option = st.selectbox(
            "Choose data source:",
            [
                "Mock GW Events API",
                "Mock GRB Catalog API", 
                "Mock Neutrino Events API",
                "Custom API Endpoint"
            ]
        )
        
        if api_option == "Custom API Endpoint":
            api_url = st.text_input("API URL:", placeholder="https://api.example.com/events")
            api_key = st.text_input("API Key (optional):", type="password")
        
        col_api1, col_api2 = st.columns(2)
        with col_api1:
            start_date = st.date_input("Start date", datetime.now().date() - timedelta(days=7))
        with col_api2:
            end_date = st.date_input("End date", datetime.now().date())
        
        if st.button("üåê **Fetch Real Data**", key="fetch_api"):
            with st.spinner("Fetching data from astronomical databases..."):
                # Simulate API call with realistic data
                time.sleep(2)  # Simulate network delay
                
                # Generate mock API response
                n_api_events = np.random.randint(20, 100)
                api_data = {
                    'dt': np.random.exponential(0.5, n_api_events),
                    'dtheta': np.random.exponential(0.05, n_api_events),
                    'strength_ratio': np.random.lognormal(0.5, 1, n_api_events),
                    'ra': np.random.uniform(0, 360, n_api_events),
                    'dec': np.random.uniform(-90, 90, n_api_events),
                    'api_source': [api_option] * n_api_events,
                    'fetch_time': [datetime.now()] * n_api_events
                }
                
                # Add messenger types based on API source
                if "GW" in api_option:
                    api_data['m1'] = ['GW'] * n_api_events
                    api_data['m2'] = np.random.choice(['Gamma', 'Optical'], n_api_events)
                elif "GRB" in api_option:
                    api_data['m1'] = ['Gamma'] * n_api_events
                    api_data['m2'] = np.random.choice(['Optical', 'Radio'], n_api_events)
                else:
                    messengers = ['GW', 'Gamma', 'Neutrino', 'Optical', 'Radio']
                    api_data['m1'] = np.random.choice(messengers, n_api_events)
                    api_data['m2'] = np.random.choice(messengers, n_api_events)
                
                df = pd.DataFrame(api_data)
                st.session_state.current_data = df
                st.session_state.api_data_cache[api_option] = df
                
                st.success(f"‚úÖ Fetched {len(df)} events from {api_option}")
                st.dataframe(df.head(), width="stretch")
    
    with tab4:
        st.markdown("### Real-time Event Simulation")
        
        col_rt1, col_rt2 = st.columns(2)
        with col_rt1:
            sim_rate = st.slider("Events per minute", 1, 10, 3)
        with col_rt2:
            rt_duration = st.slider("Simulation duration (minutes)", 1, 60, 5)
        
        if st.button("‚ö° **Start Real-time Simulation**", key="start_realtime"):
            st.session_state.real_time_mode = True
            
            # Real-time data container
            rt_container = st.container()
            rt_data = []
            
            with rt_container:
                st.info("üî¥ **LIVE**: Real-time event simulation active")
                
                # Progress and status
                progress_bar = st.progress(0)
                status_text = st.empty()
                data_display = st.empty()
                
                for minute in range(rt_duration):
                    # Generate events for this minute
                    n_new_events = np.random.poisson(sim_rate)
                    
                    if n_new_events > 0:
                        new_events = {
                            'dt': np.random.exponential(0.1, n_new_events),
                            'dtheta': np.random.exponential(0.01, n_new_events),
                            'strength_ratio': np.random.lognormal(1, 0.5, n_new_events),
                            'ra': np.random.uniform(0, 360, n_new_events),
                            'dec': np.random.uniform(-90, 90, n_new_events),
                            'm1': np.random.choice(['GW', 'Gamma', 'Neutrino'], n_new_events),
                            'm2': np.random.choice(['Optical', 'Radio'], n_new_events),
                            'timestamp': [datetime.now()] * n_new_events
                        }
                        
                        rt_data.extend([dict(zip(new_events.keys(), values)) 
                                       for values in zip(*new_events.values())])
                    
                    # Update display
                    progress_bar.progress((minute + 1) / rt_duration)
                    status_text.text(f"Minute {minute + 1}/{rt_duration} - {len(rt_data)} total events detected")
                    
                    if rt_data:
                        df_rt = pd.DataFrame(rt_data)
                        data_display.dataframe(df_rt.tail(10), width="stretch")
                    
                    time.sleep(1)  # Simulate 1 minute intervals
                
                if rt_data:
                    df_final = pd.DataFrame(rt_data)
                    st.session_state.current_data = df_final
                    st.success(f"‚úÖ Real-time simulation complete: {len(df_final)} events collected")
    
    st.markdown('</div>', unsafe_allow_html=True)

with col2:
    # Simple status panel
    st.markdown("### üìä System Status")
    
    # Model status
    if st.session_state.model_loaded:
        st.markdown('<span class="status-badge status-success">ü§ñ Model Ready</span>', unsafe_allow_html=True)
    else:
        st.markdown('<span class="status-badge status-warning">‚ö†Ô∏è No Model</span>', unsafe_allow_html=True)
    
    # Data status
    if st.session_state.current_data is not None:
        st.markdown('<span class="status-badge status-success">üìä Data Loaded</span>', unsafe_allow_html=True)
        st.metric("Events", len(st.session_state.current_data))
    else:
        st.markdown('<span class="status-badge status-info">‚ÑπÔ∏è No Data</span>', unsafe_allow_html=True)
    
    # Analysis status
    if st.session_state.results is not None:
        st.markdown('<span class="status-badge status-success">‚úÖ Analysis Complete</span>', unsafe_allow_html=True)
        positive_count = len(st.session_state.results[st.session_state.results['pred_label'] == 1])
        st.metric("Associations Found", positive_count)
    else:
        st.markdown('<span class="status-badge status-info">‚è≥ Ready to Analyze</span>', unsafe_allow_html=True)

# Data overview section (only if data is loaded)
if st.session_state.current_data is not None:
    df = st.session_state.current_data
    
    st.markdown("---")
    st.markdown("## üìã **Data Overview & Quality Assessment**")
    
    # Enhanced metrics with better styling
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.markdown("""
        <div class="metric-container">
            <h3>üìä</h3>
            <h2>{}</h2>
            <p>Total Events</p>
        </div>
        """.format(len(df)), unsafe_allow_html=True)
    
    with col2:
        unique_messengers = set()
        if 'm1' in df.columns and 'm2' in df.columns:
            unique_messengers.update(df['m1'].unique())
            unique_messengers.update(df['m2'].unique())
        st.markdown("""
        <div class="metric-container">
            <h3>üåå</h3>
            <h2>{}</h2>
            <p>Messenger Types</p>
        </div>
        """.format(len(unique_messengers)), unsafe_allow_html=True)
    
    with col3:
        time_span = df['dt'].max() - df['dt'].min() if 'dt' in df.columns else 0
        st.markdown("""
        <div class="metric-container">
            <h3>‚è±Ô∏è</h3>
            <h2>{:.1f}s</h2>
            <p>Time Span</p>
        </div>
        """.format(time_span), unsafe_allow_html=True)
    
    with col4:
        max_separation = df['dtheta'].max() if 'dtheta' in df.columns else 0
        st.markdown("""
        <div class="metric-container">
            <h3>üìê</h3>
            <h2>{:.2f}¬∞</h2>
            <p>Max Angular Sep</p>
        </div>
        """.format(max_separation), unsafe_allow_html=True)
    
    with col5:
        data_quality = (1 - df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100
        quality_color = "success" if data_quality > 90 else "warning" if data_quality > 70 else "danger"
        st.markdown("""
        <div class="metric-container">
            <h3>‚úÖ</h3>
            <h2>{:.1f}%</h2>
            <p>Data Quality</p>
        </div>
        """.format(data_quality), unsafe_allow_html=True)
    
    # Enhanced data preview with interactive elements
    with st.expander("üîç **Interactive Data Explorer**", expanded=False):
        col_filter1, col_filter2, col_filter3 = st.columns(3)
        
        with col_filter1:
            if 'm1' in df.columns:
                messenger_filter = st.multiselect(
                    "Filter by messenger type (m1):",
                    options=df['m1'].unique(),
                    default=df['m1'].unique()
                )
                df_filtered = df[df['m1'].isin(messenger_filter)] if messenger_filter else df
            else:
                df_filtered = df
        
        with col_filter2:
            if 'dt' in df.columns:
                dt_range = st.slider(
                    "Time difference range (s):",
                    float(df['dt'].min()), float(df['dt'].max()),
                    (float(df['dt'].min()), float(df['dt'].max()))
                )
                df_filtered = df_filtered[
                    (df_filtered['dt'] >= dt_range[0]) & 
                    (df_filtered['dt'] <= dt_range[1])
                ]
        
        with col_filter3:
            if 'dtheta' in df.columns:
                dtheta_range = st.slider(
                    "Angular separation range (¬∞):",
                    float(df['dtheta'].min()), float(df['dtheta'].max()),
                    (float(df['dtheta'].min()), float(df['dtheta'].max()))
                )
                df_filtered = df_filtered[
                    (df_filtered['dtheta'] >= dtheta_range[0]) & 
                    (df_filtered['dtheta'] <= dtheta_range[1])
                ]
        
        st.dataframe(df_filtered, width="stretch", height=300)
        st.caption(f"Showing {len(df_filtered)} of {len(df)} events")
    
    # Analysis section with enhanced UI
    st.markdown("---")
    st.markdown('<div class="analysis-section">', unsafe_allow_html=True)
    st.markdown("## üöÄ **AI-Powered Multimessenger Analysis**")
    
    # Analysis controls
    col_analysis1, col_analysis2, col_analysis3 = st.columns([2, 1, 1])
    
    with col_analysis1:
        st.markdown("### Ready for Analysis")
        if st.session_state.model_loaded:
            st.success("ü§ñ AI model loaded and ready")
        else:
            st.warning("‚ö†Ô∏è Please select an AI model first")
    
    with col_analysis2:
        if st.button("üßπ **Clear Results**", type="secondary"):
            st.session_state.results = None
            st.success("‚úÖ Results cleared")
    
    with col_analysis3:
        confidence_display = st.empty()
        confidence_display.info(f"üéØ Threshold: {threshold:.2f}")
    
    # Main analysis button with enhanced styling
    analysis_key = f"analyze_enhanced_{len(df)}_{hash(str(df.iloc[0].to_dict()) if len(df) > 0 else 'empty')}"
    
    if st.button("üîç **Run Advanced AI Analysis**", key=analysis_key, type="primary"):
        if not st.session_state.model_loaded or model is None:
            st.error("‚ùå Please select a trained AI model first!")
        else:
            # Enhanced progress display
            progress_container = st.container()
            with progress_container:
                progress_col1, progress_col2 = st.columns([3, 1])
                
                with progress_col1:
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                
                with progress_col2:
                    stage_indicator = st.empty()
                
                try:
                    # Stage 1: Data preparation
                    stage_indicator.info("üìä Stage 1/4")
                    status_text.text("üî¨ Preparing and validating data...")
                    progress_bar.progress(10)
                    time.sleep(0.5)
                    
                    # Stage 2: Feature engineering
                    stage_indicator.info("üîß Stage 2/4")
                    status_text.text("üß† Engineering features for AI model...")
                    progress_bar.progress(30)
                    time.sleep(0.5)
                    
                    # Stage 3: AI inference
                    stage_indicator.info("ü§ñ Stage 3/4")
                    status_text.text("üöÄ Running AI inference on multimessenger data...")
                    progress_bar.progress(60)
                    
                    # Run the actual prediction
                    df_pred = predict_df(df, model, scaler=scaler, threshold=threshold)
                    progress_bar.progress(85)
                    
                    # Stage 4: Post-processing
                    stage_indicator.info("üìà Stage 4/4")
                    status_text.text("üìä Processing results and generating insights...")
                    
                    # Add enhanced metrics to results
                    df_pred['confidence_category'] = pd.cut(
                        df_pred['pred_prob'], 
                        bins=[0, 0.3, 0.7, 1.0], 
                        labels=['Low', 'Medium', 'High']
                    )
                    
                    # Add risk assessment
                    df_pred['significance'] = (
                        df_pred['pred_prob'] * 
                        (1 / (df_pred['dt'] + 0.1)) * 
                        (1 / (df_pred['dtheta'] + 0.01))
                    )
                    
                    progress_bar.progress(100)
                    time.sleep(0.5)
                    
                    # Store results
                    st.session_state.results = df_pred
                    
                    # Clear progress indicators
                    progress_container.empty()
                    
                    # Success message with stats
                    positive_count = len(df_pred[df_pred['pred_label'] == 1])
                    high_conf_count = len(df_pred[df_pred['pred_prob'] >= 0.8])
                    
                    st.success(f"""
                    ‚úÖ **Analysis Complete!** 
                    Found {positive_count} positive associations 
                    ({high_conf_count} high confidence)
                    """)
                    
                    # Add simple report download functionality
                    st.markdown("### üìÑ Download Analysis Report")
                    
                    # Generate the report automatically
                    analysis_params = {
                        'threshold': threshold,
                        'model': model_choice if model_choice != "(none)" else 'AI Model'
                    }
                    
                    report_content = generate_simple_report(df_pred, analysis_params)
                    
                    # Create downloadable file
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"multimessenger_analysis_report_{timestamp}.txt"
                    
                    # Use streamlit's built-in download_button
                    st.download_button(
                        label="üìÑ Download Analysis Report",
                        data=report_content,
                        file_name=filename,
                        mime="text/plain",
                        type="primary"
                    )
                    
                except Exception as e:
                    progress_container.empty()
                    st.error(f"‚ùå Analysis failed: {e}")
                    
                    if show_debug:
                        with st.expander("üêõ Debug Information"):
                            import traceback
                            st.code(traceback.format_exc())
    
    st.markdown('</div>', unsafe_allow_html=True)

# Enhanced Results Section
if st.session_state.results is not None:
    df_pred = st.session_state.results
    
    st.markdown("---")
    st.markdown('<div class="results-header">üéØ Advanced Analysis Results</div>', unsafe_allow_html=True)
    
    # Enhanced results metrics
    total_events = len(df_pred)
    high_confidence = len(df_pred[df_pred['pred_prob'] >= 0.8])
    medium_confidence = len(df_pred[(df_pred['pred_prob'] >= 0.5) & (df_pred['pred_prob'] < 0.8)])
    positive_associations = len(df_pred[df_pred['pred_label'] == 1])
    avg_confidence = df_pred['pred_prob'].mean()
    max_significance = df_pred['significance'].max() if 'significance' in df_pred.columns else 0
    
    # Results overview with enhanced styling
    col1, col2, col3, col4, col5, col6 = st.columns(6)
    
    metrics_data = [
        ("üî¥", high_confidence, "High Confidence", f"{high_confidence/total_events*100:.1f}%"),
        ("üü°", medium_confidence, "Medium Confidence", f"{medium_confidence/total_events*100:.1f}%"),
        ("‚úÖ", positive_associations, "Positive Associations", f"Threshold: {threshold}"),
        ("üìä", f"{avg_confidence:.3f}", "Average Confidence", "Overall Score"),
        ("üåü", f"{max_significance:.2f}", "Max Significance", "Highest Priority"),
        ("üìà", f"{total_events}", "Total Analyzed", "Events Processed")
    ]
    
    for i, (icon, value, label, delta) in enumerate(metrics_data):
        with [col1, col2, col3, col4, col5, col6][i]:
            st.markdown(f"""
            <div class="metric-container">
                <h3>{icon}</h3>
                <h2>{value}</h2>
                <p>{label}</p>
                <small>{delta}</small>
            </div>
            """, unsafe_allow_html=True)
    
    # Enhanced results tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üéØ **Priority Events**", 
        "üìä **All Results**", 
        "üìà **Advanced Visualizations**",
        "üó∫Ô∏è **Sky Maps**",
        "üìã **Scientific Analysis**"
    ])
    
    with tab1:
        st.markdown("### üö® High-Priority Multimessenger Associations")
        
        # Priority filtering
        priority_threshold = st.slider("Priority threshold:", 0.0, 1.0, 0.7, 0.05)
        high_priority = df_pred[df_pred['pred_prob'] >= priority_threshold].sort_values('pred_prob', ascending=False)
        
        if len(high_priority) > 0:
            st.markdown(f"**{len(high_priority)} high-priority associations found:**")
            
            # Enhanced table with color coding
            def highlight_confidence(val):
                if val >= 0.8:
                    return 'background-color: rgba(0, 200, 81, 0.3)'
                elif val >= 0.6:
                    return 'background-color: rgba(255, 187, 51, 0.3)'
                else:
                    return 'background-color: rgba(255, 68, 68, 0.3)'
            
            styled_df = high_priority[['m1', 'm2', 'dt', 'dtheta', 'strength_ratio', 'pred_prob', 'pred_label']].style.applymap(
                highlight_confidence, subset=['pred_prob']
            )
            
            st.dataframe(styled_df, width="stretch")
            
            # Alert generation with enhanced options
            col_alert1, col_alert2 = st.columns(2)
            with col_alert1:
                alert_format = st.selectbox("Alert format:", ["CSV", "JSON", "XML"])
            with col_alert2:
                include_metadata = st.checkbox("Include analysis metadata", True)
            
            if st.button("üö® **Generate Priority Alerts**", key="generate_priority_alerts"):
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                
                try:
                    if alert_format == "CSV":
                        alert_data = high_priority.to_csv(index=False)
                        st.download_button(
                            label=f"üì• Download {alert_format} Alert File",
                            data=alert_data,
                            file_name=f"priority_alerts_{timestamp}.csv",
                            mime="text/csv"
                        )
                    elif alert_format == "JSON":
                        alert_data_dict = {
                            "generated_at": timestamp,
                            "threshold": priority_threshold,
                            "total_events": len(high_priority),
                            "events": high_priority.to_dict('records')
                        }
                        alert_data = json.dumps(alert_data_dict, indent=2, default=str)
                        st.download_button(
                            label=f"üì• Download {alert_format} Alert File",
                            data=alert_data,
                            file_name=f"priority_alerts_{timestamp}.json",
                            mime="application/json"
                        )
                    elif alert_format == "XML":
                        # Simple XML format
                        xml_data = f"""<?xml version="1.0" encoding="UTF-8"?>
<priority_alerts>
    <metadata>
        <generated_at>{timestamp}</generated_at>
        <threshold>{priority_threshold}</threshold>
        <total_events>{len(high_priority)}</total_events>
    </metadata>
    <events>
"""
                        for _, row in high_priority.iterrows():
                            xml_data += f"""        <event>
            <m1>{row.get('m1', 'N/A')}</m1>
            <m2>{row.get('m2', 'N/A')}</m2>
            <confidence>{row['pred_prob']:.4f}</confidence>
            <time_diff>{row.get('dt', 'N/A')}</time_diff>
            <angular_sep>{row.get('dtheta', 'N/A')}</angular_sep>
        </event>
"""
                        xml_data += """    </events>
</priority_alerts>"""
                        
                        st.download_button(
                            label=f"üì• Download {alert_format} Alert File",
                            data=xml_data,
                            file_name=f"priority_alerts_{timestamp}.xml",
                            mime="application/xml"
                        )
                    
                    st.success(f"‚úÖ Alert file ready for download in {alert_format} format!")
                    
                except Exception as e:
                    st.error(f"Error generating alert file: {str(e)}")
        else:
            st.info(f"No associations found above {priority_threshold:.2f} confidence threshold")
    
    with tab2:
        st.markdown("### üìã Complete Analysis Results")
        
        # Results filtering and sorting
        col_sort1, col_sort2, col_sort3 = st.columns(3)
        with col_sort1:
            sort_by = st.selectbox("Sort by:", ["pred_prob", "dt", "dtheta", "significance"])
        with col_sort2:
            sort_order = st.selectbox("Order:", ["Descending", "Ascending"])
        with col_sort3:
            max_display = st.number_input("Max rows to display:", 10, 1000, 200)
        
        df_display = df_pred.sort_values(
            sort_by, 
            ascending=(sort_order == "Ascending")
        ).head(max_display)
        
        st.dataframe(df_display, width="stretch", height=400)
        
        # Enhanced download options
        col_dl1, col_dl2, col_dl3 = st.columns(3)
        
        with col_dl1:
            csv_data = df_display.to_csv(index=False)
            st.download_button(
                label="üì• **Download CSV**",
                data=csv_data,
                file_name=f'analysis_results_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                mime='text/csv',
                type="secondary"
            )
        
        with col_dl2:
            json_data = df_display.to_json(orient='records', indent=2)
            st.download_button(
                label="üì• **Download JSON**",
                data=json_data,
                file_name=f'analysis_results_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json',
                mime='application/json',
                type="secondary"
            )
        
        with col_dl3:
            # Create summary report
            summary_report = f"""# Multimessenger Analysis Report
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## Summary Statistics
- Total Events Analyzed: {total_events}
- Positive Associations: {positive_associations} ({positive_associations/total_events*100:.1f}%)
- High Confidence (>0.8): {high_confidence} ({high_confidence/total_events*100:.1f}%)
- Average Confidence: {avg_confidence:.3f}
- Analysis Threshold: {threshold}

## Model Information
- Model Type: {metadata.get('best_model', 'Unknown') if metadata else 'Unknown'}
- Model AUC: {metadata.get('best_auc', 'N/A') if metadata else 'N/A'}

## Top 10 Associations
{df_display.head(10)[['m1', 'm2', 'dt', 'dtheta', 'pred_prob']].to_string() if len(df_display) > 0 else 'No data available'}
"""
            st.download_button(
                label="üìÑ **Download Report**",
                data=summary_report,
                file_name=f'analysis_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.md',
                mime='text/markdown',
                type="secondary"
            )
    
    # Continue with visualization tabs...
    with tab3:
        st.markdown("### üìà Advanced Statistical Visualizations")
        
        # Create sophisticated visualizations with proper error handling
        try:
            fig_matrix = make_subplots(
                rows=2, cols=2,
                subplot_titles=('Confidence Distribution', 'Time vs Angular Separation', 
                              'Messenger Type Analysis', 'Significance Analysis'),
                specs=[[{"secondary_y": False}, {"secondary_y": False}],
                       [{"secondary_y": False}, {"secondary_y": False}]]
            )
            
            # Confidence distribution
            fig_matrix.add_trace(
                go.Histogram(x=df_pred['pred_prob'], nbinsx=30, name='Confidence', 
                            marker_color='#1f77b4', opacity=0.7),
                row=1, col=1
            )
            
            # Time vs Angular separation with confidence coloring
            fig_matrix.add_trace(
                go.Scatter(x=df_pred['dt'], y=df_pred['dtheta'], 
                          mode='markers',
                          marker=dict(size=8, color=df_pred['pred_prob'], 
                                    colorscale='Viridis', showscale=True,
                                    colorbar=dict(title="Confidence", x=1.1)),
                          name='Events',
                          text=[f"Confidence: {p:.3f}" for p in df_pred['pred_prob']],
                          hovertemplate='Time: %{x:.2f}s<br>Angle: %{y:.2f}¬∞<br>%{text}<extra></extra>'),
                row=1, col=2
            )
            
            # Messenger type analysis
            if 'm1' in df_pred.columns and 'm2' in df_pred.columns:
                pair_counts = df_pred.groupby(['m1', 'm2']).size().reset_index(name='count')
                pair_labels = [f"{row.m1}-{row.m2}" for _, row in pair_counts.iterrows()]
                fig_matrix.add_trace(
                    go.Bar(x=pair_labels, 
                           y=pair_counts['count'], name='Pair Counts',
                           marker_color='#ff7f0e', opacity=0.7),
                    row=2, col=1
                )
            
            # Significance analysis (create if not exists)
            if 'significance' not in df_pred.columns:
                df_pred['significance'] = (
                    df_pred['pred_prob'] * 
                    (1 / (df_pred['dt'] + 0.1)) * 
                    (1 / (df_pred['dtheta'] + 0.01))
                )
            
            fig_matrix.add_trace(
                go.Scatter(x=df_pred['pred_prob'], y=df_pred['significance'],
                          mode='markers', name='Significance vs Confidence',
                          marker=dict(size=6, color='#2ca02c', opacity=0.7),
                          text=[f"Event {i}" for i in range(len(df_pred))],
                          hovertemplate='Confidence: %{x:.3f}<br>Significance: %{y:.3f}<br>%{text}<extra></extra>'),
                row=2, col=2
            )
            
            # Update layout
            fig_matrix.update_layout(
                height=800, 
                showlegend=False, 
                title_text="Advanced Multimessenger Analysis Dashboard",
                template='plotly_white'
            )
            
            # Update axes labels
            fig_matrix.update_xaxes(title_text="Confidence", row=1, col=1)
            fig_matrix.update_yaxes(title_text="Count", row=1, col=1)
            fig_matrix.update_xaxes(title_text="Time Difference (s)", row=1, col=2)
            fig_matrix.update_yaxes(title_text="Angular Separation (¬∞)", row=1, col=2)
            fig_matrix.update_xaxes(title_text="Messenger Pairs", row=2, col=1)
            fig_matrix.update_yaxes(title_text="Count", row=2, col=1)
            fig_matrix.update_xaxes(title_text="Confidence", row=2, col=2)
            fig_matrix.update_yaxes(title_text="Significance", row=2, col=2)
            
            st.plotly_chart(fig_matrix, use_container_width=True)
            
        except Exception as e:
            st.error(f"Error generating visualizations: {str(e)}")
            st.info("Showing simplified charts instead...")
            
            # Fallback simple charts
            col_viz1, col_viz2 = st.columns(2)
            
            with col_viz1:
                fig_simple1 = px.histogram(df_pred, x='pred_prob', nbins=20, 
                                         title='Confidence Distribution',
                                         color_discrete_sequence=['#1f77b4'])
                st.plotly_chart(fig_simple1, use_container_width=True)
            
            with col_viz2:
                fig_simple2 = px.scatter(df_pred, x='dt', y='dtheta', color='pred_prob',
                                       title='Time vs Angular Separation',
                                       color_continuous_scale='Viridis')
                st.plotly_chart(fig_simple2, use_container_width=True)
        
        # Correlation analysis
        st.markdown("#### üîó Correlation Analysis")
        try:
            numeric_cols = df_pred.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 1:
                correlation_matrix = df_pred[numeric_cols].corr()
                
                fig_corr = px.imshow(correlation_matrix, 
                                   title="Feature Correlation Matrix",
                                   color_continuous_scale='RdBu_r',
                                   aspect='auto')
                fig_corr.update_layout(template='plotly_white')
                st.plotly_chart(fig_corr, use_container_width=True)
            else:
                st.info("Not enough numeric columns for correlation analysis")
        except Exception as e:
            st.error(f"Error in correlation analysis: {str(e)}")
    
    with tab4:
        st.markdown("### üó∫Ô∏è Multimessenger Sky Maps")
        
        try:
            if 'ra' in df_pred.columns and 'dec' in df_pred.columns:
                # Filter out invalid coordinates
                valid_coords = df_pred.dropna(subset=['ra', 'dec'])
                valid_coords = valid_coords[
                    (valid_coords['ra'] >= 0) & (valid_coords['ra'] <= 360) &
                    (valid_coords['dec'] >= -90) & (valid_coords['dec'] <= 90)
                ]
                
                if len(valid_coords) > 0:
                    # 3D sky map
                    ra_rad = np.radians(valid_coords['ra'])
                    dec_rad = np.radians(valid_coords['dec'])
                    
                    x = np.cos(dec_rad) * np.cos(ra_rad)
                    y = np.cos(dec_rad) * np.sin(ra_rad)
                    z = np.sin(dec_rad)
                    
                    fig_3d = go.Figure(data=go.Scatter3d(
                        x=x, y=y, z=z,
                        mode='markers',
                        marker=dict(
                            size=8,
                            color=valid_coords['pred_prob'],
                            colorscale='Viridis',
                            showscale=True,
                            colorbar=dict(title="Confidence Score")
                        ),
                        text=[f"RA: {ra:.2f}¬∞, Dec: {dec:.2f}¬∞, Conf: {conf:.3f}" 
                              for ra, dec, conf in zip(valid_coords['ra'], valid_coords['dec'], valid_coords['pred_prob'])],
                        hovertemplate='%{text}<extra></extra>'
                    ))
                    
                    fig_3d.update_layout(
                        title='3D Celestial Sphere View',
                        scene=dict(
                            xaxis_title='X (Celestial)',
                            yaxis_title='Y (Celestial)',
                            zaxis_title='Z (Celestial)',
                            camera=dict(eye=dict(x=1.5, y=1.5, z=1.5))
                        ),
                        height=600,
                        template='plotly_white'
                    )
                    st.plotly_chart(fig_3d, use_container_width=True)
                    
                    # Traditional sky map
                    fig_sky = px.scatter(valid_coords, x='ra', y='dec', color='pred_prob',
                                       title='üåå Sky Distribution of Multimessenger Associations',
                                       labels={'ra': 'Right Ascension (degrees)', 'dec': 'Declination (degrees)'},
                                       color_continuous_scale='Plasma',
                                       hover_data=['dt', 'dtheta', 'strength_ratio'])
                    
                    # Add constellation-like grid
                    fig_sky.add_hline(y=0, line_dash="dash", line_color="gray", opacity=0.5)
                    for ra in range(0, 360, 30):
                        fig_sky.add_vline(x=ra, line_dash="dot", line_color="gray", opacity=0.3)
                    
                    fig_sky.update_layout(
                        xaxis=dict(range=[0, 360], title="Right Ascension (¬∞)"),
                        yaxis=dict(range=[-90, 90], title="Declination (¬∞)"),
                        height=500,
                        template='plotly_white'
                    )
                    st.plotly_chart(fig_sky, use_container_width=True)
                    
                    st.success(f"‚úÖ Displayed {len(valid_coords)} events with valid sky coordinates")
                else:
                    st.warning("‚ö†Ô∏è No valid sky coordinates found in the dataset")
            else:
                st.info("‚ÑπÔ∏è Sky coordinates (RA/Dec) not available in dataset for sky mapping")
                
                # Generate sample sky coordinates for demonstration
                if st.button("üåü Generate Sample Sky Coordinates", key="gen_sky_coords"):
                    df_pred['ra'] = np.random.uniform(0, 360, len(df_pred))
                    df_pred['dec'] = np.random.uniform(-90, 90, len(df_pred))
                    st.success("‚úÖ Sample sky coordinates generated! Refresh the tab to see the sky maps.")
                    st.rerun()
                    
        except Exception as e:
            st.error(f"Error generating sky maps: {str(e)}")
            st.info("Unable to display sky visualizations with current data")
    
    with tab5:
        st.markdown("### üìä Scientific Analysis Tools")
        
        # Statistical tests and analysis
        col_sci1, col_sci2 = st.columns(2)
        
        with col_sci1:
            st.markdown("#### üìà Statistical Summary")
            
            # Confidence intervals
            confidence_stats = df_pred['pred_prob'].describe()
            st.markdown(f"""
            **Confidence Score Statistics:**
            - Mean: {confidence_stats['mean']:.3f}
            - Median: {confidence_stats['50%']:.3f}
            - Std Dev: {confidence_stats['std']:.3f}
            - 95th Percentile: {df_pred['pred_prob'].quantile(0.95):.3f}
            """)
            
            # Time delay analysis
            if 'dt' in df_pred.columns:
                time_stats = df_pred['dt'].describe()
                st.markdown(f"""
                **Time Delay Analysis:**
                - Mean Œît: {time_stats['mean']:.3f} s
                - Median Œît: {time_stats['50%']:.3f} s
                - 99th Percentile: {df_pred['dt'].quantile(0.99):.3f} s
                """)
        
        with col_sci2:
            st.markdown("#### üî¨ Physics Insights")
            
            # Speed of light checks
            if 'dt' in df_pred.columns and 'dtheta' in df_pred.columns:
                # Approximate distance for light travel time
                c_light = 3e8  # m/s
                typical_distance = 100 * 3.086e22  # 100 Mpc in meters
                
                light_travel_times = df_pred['dtheta'] * np.pi/180 * typical_distance / c_light
                causal_events = len(df_pred[df_pred['dt'] >= light_travel_times])
                
                st.markdown(f"""
                **Causality Analysis (@ 100 Mpc):**
                - Causally connected events: {causal_events}/{len(df_pred)}
                - Fraction: {causal_events/len(df_pred)*100:.1f}%
                """)
            
            # Messenger type preferences
            if 'm1' in df_pred.columns and 'm2' in df_pred.columns:
                high_conf_pairs = df_pred[df_pred['pred_prob'] >= 0.8]
                if len(high_conf_pairs) > 0:
                    top_pair = high_conf_pairs.groupby(['m1', 'm2']).size().idxmax()
                    st.markdown(f"""
                    **Most Significant Pairing:**
                    - {top_pair[0]} ‚Üî {top_pair[1]}
                    - High confidence events: {len(high_conf_pairs)}
                    """)
        
        # Parameter sensitivity analysis
        st.markdown("#### ‚öôÔ∏è Parameter Sensitivity Analysis")
        
        sensitivity_param = st.selectbox(
            "Parameter to analyze:",
            ['threshold', 'time_window', 'angular_resolution']
        )
        
        try:
            if sensitivity_param == 'threshold':
                # Threshold sensitivity
                thresholds = np.arange(0.1, 1.0, 0.1)
                positive_counts = []
                
                for t in thresholds:
                    count = len(df_pred[df_pred['pred_prob'] >= t])
                    positive_counts.append(count)
                
                fig_sens = px.line(x=thresholds, y=positive_counts,
                                 title='Sensitivity to Confidence Threshold',
                                 labels={'x': 'Threshold', 'y': 'Positive Associations'},
                                 template='plotly_white')
                fig_sens.add_vline(x=threshold, line_dash="dash", 
                                 annotation_text=f"Current: {threshold}")
                st.plotly_chart(fig_sens, use_container_width=True)
            else:
                st.info(f"Analysis for {sensitivity_param} not yet implemented")
        except Exception as e:
            st.error(f"Error in sensitivity analysis: {str(e)}")
        
        # Export scientific data
        st.markdown("#### üì§ Scientific Data Export")
        
        col_export1, col_export2 = st.columns(2)
        
        with col_export1:
            # Create publication-ready dataset
            pub_columns = ['m1', 'm2', 'dt', 'dtheta', 'strength_ratio', 'pred_prob', 'pred_label']
            pub_data = df_pred[[col for col in pub_columns if col in df_pred.columns]].copy()
            
            # Rename columns for publication
            column_mapping = {
                'm1': 'Messenger_1', 'm2': 'Messenger_2', 'dt': 'Time_Delay_s',
                'dtheta': 'Angular_Separation_deg', 'strength_ratio': 'Strength_Ratio',
                'pred_prob': 'AI_Confidence', 'pred_label': 'Association_Flag'
            }
            pub_data = pub_data.rename(columns={k: v for k, v in column_mapping.items() if k in pub_data.columns})
            
            pub_csv = pub_data.to_csv(index=False)
            st.download_button(
                label="üìä **Publication Dataset**",
                data=pub_csv,
                file_name=f'multimessenger_science_data_{datetime.now().strftime("%Y%m%d")}.csv',
                mime='text/csv',
                type="secondary"
            )
        
        with col_export2:
            # Create analysis metadata
            try:
                metadata_export = {
                    "analysis_timestamp": datetime.now().isoformat(),
                    "model_info": metadata if metadata else {},
                    "analysis_parameters": {
                        "threshold": threshold,
                        "total_events": total_events,
                        "positive_associations": positive_associations
                    },
                    "statistics": {
                        "mean_confidence": float(avg_confidence),
                        "high_confidence_events": high_confidence,
                        "data_quality_score": float(data_quality)
                    }
                }
                
                metadata_json = json.dumps(metadata_export, indent=2, default=str)
                st.download_button(
                    label="üìã **Analysis Metadata**",
                    data=metadata_json,
                    file_name=f'analysis_metadata_{datetime.now().strftime("%Y%m%d")}.json',
                    mime='application/json',
                    type="secondary"
                )
            except Exception as e:
                st.error(f"Error creating metadata: {str(e)}")

else:
    # No data loaded - show getting started guide
    st.markdown("---")
    st.markdown("## üöÄ **Getting Started with Multimessenger Analysis**")
    
    st.markdown("""
    <div class="input-card">
    <h3>üëã Welcome to the Multimessenger AI Observatory!</h3>
    <p>Follow these steps to start analyzing multimessenger astronomical events:</p>
    
    <ol>
    <li><strong>Select an AI Model</strong> - Choose from the trained models in the sidebar</li>
    <li><strong>Load Data</strong> - Use one of the data input methods above:
        <ul>
        <li>üöÄ Generate demo data for testing</li>
        <li>üìÇ Upload your own CSV files</li>
        <li>üåê Fetch real astronomical data via APIs</li>
        <li>‚ö° Simulate real-time event detection</li>
        </ul>
    </li>
    <li><strong>Run Analysis</strong> - Click the analysis button to process your data</li>
    <li><strong>Explore Results</strong> - View visualizations, download data, and generate alerts</li>
    </ol>
    </div>
    """, unsafe_allow_html=True)
    
    # Educational content for students
    with st.expander("üìö **Learn About Multimessenger Astronomy**"):
        st.markdown("""
        ### What is Multimessenger Astronomy?
        
        Multimessenger astronomy is a revolutionary approach that combines observations from different cosmic messengers:
        
        - **üåä Gravitational Waves**: Ripples in spacetime from accelerating massive objects
        - **üî∫ Neutrinos**: Nearly massless particles that travel through matter unimpeded  
        - **‚ö° Gamma Rays**: High-energy electromagnetic radiation
        - **üîç Optical Light**: Traditional electromagnetic observations
        - **üì° Radio Waves**: Low-energy electromagnetic signals
        
        ### Why Use AI?
        
        Machine learning helps identify subtle correlations between these different signals that might indicate they originated from the same astrophysical event, even when individual signals are weak or noisy.
        
        ### Key Parameters:
        
        - **Time Delay (Œît)**: Time difference between detection of different messengers
        - **Angular Separation (ŒîŒ∏)**: Difference in sky position between events  
        - **Strength Ratio**: Relative intensity of the two signals
        - **Confidence Score**: AI-predicted probability of true association
        """)

# Simple footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; padding: 1.5rem; background: var(--background-card); 
            border-radius: 8px; margin-top: 2rem; border: 1px solid var(--border-color);">
    <h3>üåå Multimessenger AI Observatory</h3>
    <p>Advanced AI-powered analysis platform for multimessenger astronomical events</p>
    <p><strong>Built for researchers, students, and educators</strong></p>
    <p style="font-size: 0.8rem; color: var(--text-secondary);">
        NASA Space Apps Challenge | Powered by Streamlit & Python
    </p>
</div>
""", unsafe_allow_html=True)
